from fastapi import FastAPI, Request, Form
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from dotenv import load_dotenv
from ibm_watsonx_ai.foundation_models import ModelInference
import os

# Load environment variables
load_dotenv()

API_KEY = os.getenv("IBM_API_KEY")
ENDPOINT = os.getenv("IBM_GRANITE_ENDPOINT")
MODEL_ID = os.getenv("IBM_MODEL_ID")
PROJECT_ID = os.getenv("IBM_PROJECT_ID")

# FastAPI setup
app = FastAPI()
templates = Jinja2Templates(directory="templates")
app.mount("/static", StaticFiles(directory="static"), name="static")

# Safely call model and return generated response
def query_model(prompt: str):
Â Â Â Â try:
Â Â Â Â Â Â Â Â model = ModelInference(
Â Â Â Â Â Â Â Â Â Â Â Â model_id=MODEL_ID,
Â Â Â Â Â Â Â Â Â Â Â Â project_id=PROJECT_ID,
Â Â Â Â Â Â Â Â Â Â Â Â credentials={"apikey": API_KEY, "url": ENDPOINT}
Â Â Â Â Â Â Â Â )
Â Â Â Â Â Â Â Â response = model.generate_text(
Â Â Â Â Â Â Â Â Â Â Â Â prompt=prompt,
Â Â Â Â Â Â Â Â Â Â Â Â params={"max_new_tokens": 100, "decoding_method": "greedy"}
Â Â Â Â Â Â Â Â )

Â Â Â Â Â Â Â Â # If it's a string (correct format), return it
Â Â Â Â Â Â Â Â if isinstance(response, str):
Â Â Â Â Â Â Â Â Â Â Â Â return response

Â Â Â Â Â Â Â Â # If it's a dict, try to extract result
Â Â Â Â Â Â Â Â elif isinstance(response, dict) and "results" in response:
Â Â Â Â Â Â Â Â Â Â Â Â return response["results"][0].get("generated_text", "No result found.")

Â Â Â Â Â Â Â Â # Any other format
Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â return f"âš ï¸ Unexpected response format: {response}"
Â Â Â Â except Exception as e:
Â Â Â Â Â Â Â Â return f"âš ï¸ Error while generating response: {str(e)}"

# Routes

@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
Â Â Â Â return templates.TemplateResponse("index.html", {"request": request})

@app.post("/predict", response_class=JSONResponse)
async def predict(user_input: str = Form(...)):
Â Â Â Â prompt = f"Symptoms: {user_input}\nWhat disease could it be? give 3 lines of explanation also in bullet points"
Â Â Â Â result = query_model(prompt)
Â Â Â Â # Format as bullet list
Â Â Â Â fresult = "\n".join(f"ğŸ‘‰ {item.strip()}" for item in result.split(".") if item.strip())

Â Â Â Â return {"result": fresult}

@app.post("/remedies", response_class=JSONResponse)
async def remedies(user_input: str = Form(...)):
Â Â Â Â prompt = f"Disease or Symptoms: {user_input}\nGive a list of natural remedies (max 6) give in points line by line."
Â Â Â Â import re
Â Â Â Â result = query_model(prompt)
Â Â Â Â fresult= "\n".join(
Â Â Â Â f" {item.strip()}"
Â Â Â Â for item in re.split(r"\d+\.\s*", result)
Â Â Â Â if item.strip()
)
Â Â Â Â return {"result": fresult}

@app.get("/tips", response_class=JSONResponse)
async def tips():
Â Â Â Â prompt = "Give 12 health tips"
Â Â Â Â result = query_model(prompt)
Â Â Â Â return {"result": result}
@app.post("/chat", response_class=JSONResponse)
async def chat(user_input: str = Form(...)):
Â Â Â Â prompt = (
Â Â Â Â Â Â Â Â f"You are a smart and helpful health assistant. "
Â Â Â Â Â Â Â Â f"Respond to the user's health questions clearly and accurately.\n\n"
Â Â Â Â Â Â Â Â f"User: {user_input}\n"
Â Â Â Â Â Â Â Â f"Assistant:"
Â Â Â Â )
Â Â Â Â result = query_model(prompt)
Â Â Â Â return {"result": result}
@app.post("/treatment", response_class=JSONResponse)
async def treatment(user_input: str = Form(...)):
Â Â Â Â prompt = (
Â Â Â Â Â Â Â Â f"Condition and patient details: {user_input}\n"
Â Â Â Â Â Â Â Â f"Generate a concise treatment plan with exactly 3 points for each section:\n"
Â Â Â Â Â Â Â Â f"1. Medications\n"
Â Â Â Â Â Â Â Â f"2. Lifestyle changes\n"
Â Â Â Â Â Â Â Â f"3. Follow-up care"
Â Â Â Â )

Â Â Â Â result = query_model(prompt)

Â Â Â Â # Return plain text as result
Â Â Â Â return {"plan": result.strip()}
@app.post("/ai-insights", response_class=JSONResponse)
async def ai_insights(
Â Â Â Â heart_rate: str = Form(...),
Â Â Â Â blood_pressure: str = Form(...),
Â Â Â Â glucose: str = Form(...)
):
Â Â Â Â # Combine into prompt
Â Â Â Â user_data = (
Â Â Â Â Â Â Â Â f"Heart Rate: {heart_rate}\n"
Â Â Â Â Â Â Â Â f"Blood Pressure (systolic): {blood_pressure}\n"
Â Â Â Â Â Â Â Â f"Blood Glucose: {glucose}"
Â Â Â Â )

Â Â Â Â prompt = (
Â Â Â Â Â Â Â Â f"Analyze the following 7-day health data trends:\n{user_data}\n\n"
Â Â Â Â Â Â Â Â f"Give 2 potential health insights and 3 improvement recommendations."
Â Â Â Â )

Â Â Â Â result = query_model(prompt)
Â Â Â Â return {"result": result}


# Optional: Quick frontend test
@app.post("/chat-test", response_class=JSONResponse)
async def chat_test(user_input: str = Form(...)):
Â Â Â Â return {"result": f"âœ… Echo: {user_input}"}
    
